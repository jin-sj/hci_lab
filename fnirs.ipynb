{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_START = \"baselinestart\"\n",
    "BASELINE_END = \"baselineend\"\n",
    "EASY_START = \"easystart\"\n",
    "EASY_END = \"easyend\"\n",
    "HARD_START = \"hardstart\"\n",
    "HARD_END = \"hardend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gets the row blocks for easy and hard tasks\n",
    "\"\"\"\n",
    "def read_data(fnirs_path, marker_path):\n",
    "    fnirs_df =  pd.read_csv(fnirs_path, sep='\\t', skiprows=range(4), index_col=False)\n",
    "    marker_df = pd.read_csv(marker_path, sep='\\t', skiprows=range(4), index_col=False)\n",
    "    \n",
    "    merged_df = pd.merge(fnirs_df, marker_df, on=\"Matlab_now\", how=\"left\")\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_blocks(merged_df):\n",
    "    easy_start_rows = merged_df.index[merged_df.Stimulus_Label == EASY_START].tolist()\n",
    "    easy_end_rows = merged_df.index[merged_df.Stimulus_Label == EASY_END].tolist()\n",
    "    hard_start_rows = merged_df.index[merged_df.Stimulus_Label == HARD_START].tolist()\n",
    "    hard_end_rows = merged_df.index[merged_df.Stimulus_Label == HARD_END].tolist()\n",
    "    \n",
    "    easy_rows = list(zip(easy_start_rows, easy_end_rows))\n",
    "    hard_rows = list(zip(hard_start_rows, hard_end_rows))\n",
    "    \n",
    "    return (easy_rows, hard_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Return subset of df determined by the indices of the row blocks\n",
    "\"\"\"\n",
    "def get_subsets(merged_df, row_blocks):\n",
    "    tables = []\n",
    "    column_names = [\"Matlab_now\", \"A-DC1\", \"A-DC2\", \"A-DC3\", \"A-DC4\", \"A-DC5\",\n",
    "                    \"A-DC6\", \"A-DC7\", \"A-DC8\", \"B-DC1\", \"B-DC2\", \"B-DC3\", \n",
    "                    \"B-DC4\", \"B-DC5\", \"B-DC6\", \"B-DC7\", \"B-DC8\"]\n",
    "    column_indices = [merged_df.columns.get_loc(c) for c in column_names]\n",
    "    for row_block in row_blocks:\n",
    "        df = merged_df.iloc[row_block[0]:row_block[1], column_indices]\n",
    "        start_time = df.iloc[0][\"Matlab_now\"]\n",
    "        df[\"Matlab_now\"] = df[\"Matlab_now\"] - start_time\n",
    "\n",
    "        tables.append(df)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"runs polyfit on the timeseries data\n",
    "    :param tables: table of blocks of easy / hard tasks\n",
    "    :param difficulty: 0 - easy, 1 - hard; labeling process\n",
    "    \n",
    "    :return: numpy array of\n",
    "    feature_row: \n",
    "        AC-1 gradient, AC-1 intercept, AC-1 mean, AC-2 gradient ... DC-8 gradient DC-8 intercept DC-8 mean difficulty\n",
    "    \n",
    "    \n",
    "    Dictionary of key: channel\n",
    "                           value: (gradient, mean, difficulty)\n",
    "\"\"\"\n",
    "def extract_features(tables, difficulty):\n",
    "    arr = np.empty((0, 49))\n",
    "    for table in tables:\n",
    "        x = table[\"Matlab_now\"].values\n",
    "        cols = table.columns[1:]\n",
    "        feature_row = []\n",
    "        for col in cols:\n",
    "            y = table[col].values\n",
    "            gradient, intercept = np.poly1d(np.polyfit(x, y, 1))\n",
    "            avg = table[col].mean()\n",
    "            \n",
    "            feature_row = feature_row + [gradient, intercept, avg]\n",
    "        feature_row.append(difficulty)\n",
    "        feature_row = np.array(feature_row)\n",
    "        \n",
    "        arr = np.vstack([arr, feature_row])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract features from given dataset\n",
    "    :param data_path: Directory containing the files\n",
    "    \n",
    "    :return: gets all the easy and hard features from a given dataset\n",
    "\"\"\"\n",
    "def get_features_for_dataset(data_path):\n",
    "    fnirs_path = os.path.join(os.getcwd(), data_path, \"fNIRSdata.txt\")\n",
    "    marker_path = os.path.join(os.getcwd(), data_path, \"markers.txt\")\n",
    "    merged_df = read_data(fnirs_path, marker_path)\n",
    "    easy_rows, hard_rows = get_row_blocks(merged_df)\n",
    "    \n",
    "    easy_tables = get_subsets(merged_df, easy_rows)\n",
    "    hard_tables = get_subsets(merged_df, hard_rows)\n",
    "    easy_feature_rows = extract_features(easy_tables, 0)\n",
    "    hard_feature_rows = extract_features(hard_tables, 1)\n",
    "    \n",
    "    features = np.vstack([easy_feature_rows, hard_feature_rows])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_902 = get_features_for_dataset(\"/Users/sjjin/workspace/hci_lab/data/S902/2015-02-26_11-24-48-120\")\n",
    "features_903 = get_features_for_dataset(\"/Users/sjjin/workspace/hci_lab/data/S903/2015-02-27_13-20-42-120\")\n",
    "features_904 = get_features_for_dataset(\"/Users/sjjin/workspace/hci_lab/data/S904/2015-02-27_15-30-27-120\")\n",
    "features_905 = get_features_for_dataset(\"/Users/sjjin/workspace/hci_lab/data/S905/2015-03-02_13-14-35-120\")\n",
    "features_906 = get_features_for_dataset(\"/Users/sjjin/workspace/hci_lab/data/S906/2015-03-05_11-17-38-120\")\n",
    "\n",
    "train_set = np.vstack([features_902, features_903, features_904, features_905])\n",
    "test_set = features_906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_set[:, :-1]\n",
    "train_y = train_set[:, -1]\n",
    "test_x = test_set[:, :-1]\n",
    "test_y = test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 48)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47619047619047616"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pred = logisticRegr.predict(test_x)\n",
    "accuracy_score(test_y, log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_set_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
